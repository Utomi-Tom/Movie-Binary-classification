{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXfsaLUy0ktXaotAruSj6S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utomi-Tom/Movie-Binary-classification/blob/main/IMBD_movie_classification_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction on the IMDB review project\n",
        "The IMDB dataset consist of: a set of 50,000 highly polarized reviews from the\n",
        "Internet Movie Database. They’re split into 25,000 reviews for training and 25,000\n",
        "reviews for testing, each set consisting of 50% negative and 50% positive reviews.\n",
        "\n",
        "\n",
        "Just like the MNIST dataset, the IMDB dataset comes packaged with Keras. It has\n",
        "already been preprocessed: the reviews (sequences of words) have been turned into\n",
        "sequences of integers, where each integer stands for a specific word in a dictionary."
      ],
      "metadata": {
        "id": "BknqXcLKHUIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing library"
      ],
      "metadata": {
        "id": "JIyCX4rtWQ4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The following code will load the dataset (when you run it the first time, about\n",
        "80 MB of data will be downloaded to your machine)."
      ],
      "metadata": {
        "id": "hgDFaYwfWNgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MySbF3kKGedj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset \n",
        "(x_tr, y_tr), (x_tt, y_tt) = keras.datasets.imdb.load_data(num_words=10000)"
      ],
      "metadata": {
        "id": "7K-r3p__HK6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99eef2e0-4f4a-4587-a7e8-0d43f15e7b56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The argument *num_words* =10000 means you’ll only keep the top 10,000 most frequently\n",
        "occurring words in the training data. Rare words will be discarded. This allows\n",
        "you to work with vector data of manageable size."
      ],
      "metadata": {
        "id": "PrfisSqfJHQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = keras.datasets.imdb.get_word_index()"
      ],
      "metadata": {
        "id": "0g4tysPdKIMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d6509d-e5d4-42a4-ec4f-35c0a140bcea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above code is how I quickly decode one of these reviews back to English\n",
        "words:\n",
        "\n",
        "\n",
        "*get_word_index* is a dictionary, mapping\n",
        "words to an integer index."
      ],
      "metadata": {
        "id": "-KDgRXkWKHVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_word_ind = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "metadata": {
        "id": "AlhVNY7cLpt3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code reverses the mapping process, by mapping\n",
        "integer indices to words."
      ],
      "metadata": {
        "id": "sAzbWv19Mr0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_review = \"\".join([r_word_ind.get(i - 3, \"?\") for i in x_tr[3]])"
      ],
      "metadata": {
        "id": "LFhyhKNeMmAL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_review\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "m2dq6ImtNhtE",
        "outputId": "d61fef18-ad4d-4af3-f2e2-791c62cd2358"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"?the??atstorytellingthetraditionalsortmanyyearsaftertheeventicanstillseeinmy?eyeanelderlyladymyfriend'smotherretellingthebattleof?shemakesthecharacterscomealiveherpassionisthatofaneyewitnessonetotheeventsonthe?heathamileorsofromwhereshelivesbrbrofcourseithappenedmanyyearsbeforeshewasbornbutyouwouldn'tguessfromthewayshetellsitthesamestoryistoldinbarsthelengthand?ofscotlandasidiscusseditwithafriendonenightin?alocalcutintogivehisversionthediscussioncontinuedtoclosingtimebrbrstoriespasseddownlikethisbecomepartofourbeingwhodoesn'trememberthestoriesourparentstolduswhenwewerechildrentheybecomeourinvisibleworldandaswegrowoldertheymaybestillserveasinspirationorasanemotional?factandfictionblendwith?rolemodelswarningstories?magicandmysterybrbrmynameis?likemygrandfatherandhisgrandfatherbeforehimourprotagonistintroduceshimselftousandalsointroducesthestorythatstretchesbackthroughgenerationsitproducesstorieswithinstoriesstoriesthatevokethe?wonderofscotlanditsruggedmountains?in?thestuffoflegendyet?is?inrealitythisiswhatgivesititsspecialcharmithasaroughbeautyandauthenticity?withsomeofthefinest?singingyouwilleverhearbrbr??visitshisgrandfatherinhospitalshortlybeforehisdeathheburnswithfrustrationpartofhim?tobeinthetwentyfirstcenturytohangoutin?butheisraisedonthewestern?amonga?speakingcommunitybrbryetthereisadeeperconflictwithinhimhe?toknowthetruththetruthbehindhis?ancientstorieswheredoesfictionendandhewantstoknowthetruthbehindthedeathofhisparentsbrbrheispulledtomakealast?journeytothe?ofoneof?most?mountainscanthetruthbetoldorisitallinstoriesbrbrinthisstoryaboutstorieswe?bloodybattles?loversthe?ofoldandthesometimesmore??ofacceptedtruthindoingsoweeachconnectwith?ashelivesthestoryofhisownlifebrbr?the??isprobablythemosthonest?andgenuinelybeautifulfilmofscotlandevermadelike?igotslightlyannoyedwiththe?ofhangingstoriesonmorestoriesbutalsolike?i?thisonceisawthe?picture'forgettheboxoffice?ofbraveheartanditslikeyoumighteven?the?famous?ofthewickermantoseeafilmthatistruetoscotlandthisoneisprobablyuniqueifyoumaybe?onitdeeplyenoughyoumightevenre?thepowerofstorytellingandtheageoldquestionofwhethertherearesometruthsthatcannotbetoldbutonlyexperienced\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variables **x_tr and x_tt** are lists of reviews; each review is a list of\n",
        "word indices (encoding a sequence of words).**y_tr and y_tt** are\n",
        "lists of 0s and 1s, where 0 stands for negative and 1 stands for positive:"
      ],
      "metadata": {
        "id": "chbHnzzwJP85"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6a7iosllOfyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data\n",
        "\n",
        "Because I cannot feed lists of integers into a neural network. I need to turn your lists into tensors and there are two ways to do that.\n",
        "\n",
        "\n",
        "*  Pad your lists so that they all have the same length, turn them into an integer\n",
        "tensor of shape (samples, word_indices), and then use as the first layer in\n",
        "your network a layer capable of handling such integer tensors. \n",
        "*  One-hot encode your lists to turn them into vectors of 0s and 1s. This would\n",
        "mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vector\n",
        "that would be all 0s except for indices 3 and 5, which would be 1s. Then you\n",
        "could use as the first layer in your network a Dense layer, capable of handling\n",
        "floating-point vector data.\n",
        "\n",
        "\n",
        "\n",
        "Let’s go with the latter solution to vectorize the data, which you’ll do manually for\n",
        "maximum clarity.\n"
      ],
      "metadata": {
        "id": "GXC_V0d_N3tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the integer sequences into a binary matrix\n",
        "\n",
        "def vectorize_seq (sequence, dim= 10000):\n",
        "  results = np.zeros((len(sequence), dim))\n",
        "  for i, sequence in enumerate(sequence):\n",
        "    results[i, sequence] = 1\n",
        "  return results"
      ],
      "metadata": {
        "id": "MuP8ZBSoNjl9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = vectorize_seq(x_tr)\n",
        "print(train_data\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3HTSHO08uig",
        "outputId": "3c64c914-e864-4048-897a-ab33c5677b8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = vectorize_seq(x_tt)\n",
        "print(test_data\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-XsEXuG88zF",
        "outputId": "3e427fd0-34d4-42c7-9ed5-b17bd5c063df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize labels as well\n",
        "\n",
        "label_train = np.asarray(y_tr).astype(\"float32\")\n",
        "label_test = np.asarray(y_tt).astype(\"float32\")"
      ],
      "metadata": {
        "id": "1-RlstMf9CoE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLhEl1934j-z",
        "outputId": "38e7415a-d1dd-4ee0-a33f-228d1a979471"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr = train_data[12000:]\n",
        "y_tr = label_train[12000:]\n",
        "\n",
        "val_train = train_data[12001:20000]\n",
        "val_label = label_train[12001:20000]\n",
        "\n",
        "test_train= train_data[20001:25000]\n",
        "test_label = label_train[20001:25000]"
      ],
      "metadata": {
        "id": "kxb-GtUG3wvN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qt4rYAaf4-MI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the data is ready to be fed into a neural network.\n",
        "\n",
        "# Building your network"
      ],
      "metadata": {
        "id": "i0r0cDtH-Lnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "5LC2T7V0-AGH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Model architecture\n",
        "model= models.Sequential()\n",
        "model.add(layers.Dense(16, activation=\"relu\", input_shape=(10000, )))\n",
        "model.add(layers.Dense(16, activation= \"relu\"))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "75BMjpAsmIth"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Optimizer and Loss functions\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop()\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True,)"
      ],
      "metadata": {
        "id": "0seKek09mOBI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model \n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "CNBjF9MPniKL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_tr, y_tr, epochs=10, batch_size=100, validation_data=(val_train, val_label))"
      ],
      "metadata": {
        "id": "bvkcQaWdn4qY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34149c90-5034-45fb-c9c5-d5596d74060a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130/130 [==============================] - 2s 9ms/step - loss: 0.4125 - accuracy: 0.8298 - val_loss: 0.2330 - val_accuracy: 0.9176\n",
            "Epoch 2/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.2144 - accuracy: 0.9226 - val_loss: 0.1297 - val_accuracy: 0.9602\n",
            "Epoch 3/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.1488 - accuracy: 0.9463 - val_loss: 0.0960 - val_accuracy: 0.9709\n",
            "Epoch 4/10\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.1091 - accuracy: 0.9618 - val_loss: 0.0707 - val_accuracy: 0.9795\n",
            "Epoch 5/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 0.0507 - val_accuracy: 0.9840\n",
            "Epoch 6/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.0260 - val_accuracy: 0.9946\n",
            "Epoch 7/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0356 - accuracy: 0.9889 - val_loss: 0.0152 - val_accuracy: 0.9976\n",
            "Epoch 8/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0093 - val_accuracy: 0.9985\n",
            "Epoch 9/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.0050 - val_accuracy: 0.9996\n",
            "Epoch 10/10\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0025 - val_accuracy: 0.9996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check learning history of the trained model\n",
        "\n",
        "history_dict = history.history\n",
        "type(history_dict)\n",
        "\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGsYCH8E7Lkz",
        "outputId": "6ffffc3d-69f3-4bcf-f36a-6b6bbc8c5934"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nnCMwzlD7VNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}